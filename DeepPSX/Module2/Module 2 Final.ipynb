{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6luPLmvf27z"
   },
   "source": [
    "##  Importing Dependencies\n",
    "   We shall start by importing all the neccessary libraries. I will explain the exact use of each library later in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FazmnFmyf270",
    "outputId": "fc1394e5-dd8c-44a6-d3ed-2a3c6ee82da5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version 1.14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\CZ\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import nltk \n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "print(\"Tensorflow Version\",tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BFnvhoNrf271"
   },
   "source": [
    "#  Dataset Preprocessing\n",
    "In this notebook, we use news data scraped from DAWN and Business Recorder websites using Selenium package on python. The final CSV has news with their respected dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "PBeW1g9uf271",
    "outputId": "ea29e404-577d-4d62-e5dc-a194f88025cb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>News</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>Cum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>Bone marrow recipients highlight consequences ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.192</td>\n",
       "      <td>-0.1779</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>Zardari signs reference to reopen case of Bhut...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-06</td>\n",
       "      <td>Grade 21 officer to head NDMA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-06</td>\n",
       "      <td>'Pakistan risks becoming a polio transmission ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.2732</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-06</td>\n",
       "      <td>2009: US considers journalist’s request for in...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date                                               News  Polarity  \\\n",
       "0 2011-01-04  Bone marrow recipients highlight consequences ...         0   \n",
       "1 2011-01-04  Zardari signs reference to reopen case of Bhut...         0   \n",
       "2 2011-01-06                      Grade 21 officer to head NDMA         0   \n",
       "3 2011-01-06  'Pakistan risks becoming a polio transmission ...         0   \n",
       "4 2011-01-06  2009: US considers journalist’s request for in...         0   \n",
       "\n",
       "   Sentiment    neg    neu    pos  compound  Cum  \n",
       "0          0  0.248  0.560  0.192   -0.1779    0  \n",
       "1          0  0.000  1.000  0.000    0.0000    0  \n",
       "2          0  0.000  1.000  0.000    0.0000    0  \n",
       "3          0  0.296  0.704  0.000   -0.2732    0  \n",
       "4          0  0.000  1.000  0.000    0.0000    0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data(filename):\n",
    "    \n",
    "    df = pd.read_csv(filename)\n",
    "    df = df.dropna()\n",
    "    df = df.reset_index()\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df = df.sort_values(by=['Date'])\n",
    "    df = df.reset_index()\n",
    "    df = df.drop(columns=['level_0','index'])\n",
    "    return df\n",
    "    \n",
    "df = load_data('All_News.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WVHcgxnAf271"
   },
   "source": [
    "The data was feature engineered and has different columns with the following interpretation:\n",
    "\n",
    "- Polarity: The price change on the date news was published as positive (1), neutral (0) and negative (-1).\n",
    "- Sentiment: Sentiment generated and engineered from Vader (NLTK Corpus) as good (1), neutral (0) and bad (-1)\n",
    "- neg: The probability of news being negative (generated from Vader).\n",
    "- neu: The probability of news being neutral (generated from Vader).\n",
    "- pos: The probability of news being positive (generated from Vader).\n",
    "- compound: The compound score of news being negative, neutral or positive scaled between -1 and 1 (generated from Vader).\n",
    "- Cum: The cumulative score of the news engineered from Polarity and Sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "id": "IVA1nKA4f272",
    "outputId": "18634735-d661-482a-8259-40c4bff10154"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>Cum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10515.000000</td>\n",
       "      <td>10515.000000</td>\n",
       "      <td>10515.000000</td>\n",
       "      <td>10515.000000</td>\n",
       "      <td>10515.000000</td>\n",
       "      <td>10515.000000</td>\n",
       "      <td>10515.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.167000</td>\n",
       "      <td>0.167000</td>\n",
       "      <td>0.076030</td>\n",
       "      <td>0.830364</td>\n",
       "      <td>0.093605</td>\n",
       "      <td>0.087019</td>\n",
       "      <td>0.167000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.799274</td>\n",
       "      <td>0.799274</td>\n",
       "      <td>0.124271</td>\n",
       "      <td>0.140714</td>\n",
       "      <td>0.109041</td>\n",
       "      <td>0.501812</td>\n",
       "      <td>0.799274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.979900</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.296000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.845000</td>\n",
       "      <td>0.071000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.128000</td>\n",
       "      <td>0.934000</td>\n",
       "      <td>0.161000</td>\n",
       "      <td>0.510600</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.821000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.773000</td>\n",
       "      <td>0.973200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Polarity     Sentiment           neg           neu           pos  \\\n",
       "count  10515.000000  10515.000000  10515.000000  10515.000000  10515.000000   \n",
       "mean       0.167000      0.167000      0.076030      0.830364      0.093605   \n",
       "std        0.799274      0.799274      0.124271      0.140714      0.109041   \n",
       "min       -1.000000     -1.000000      0.000000      0.099000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.750000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.845000      0.071000   \n",
       "75%        1.000000      1.000000      0.128000      0.934000      0.161000   \n",
       "max        1.000000      1.000000      0.821000      1.000000      0.773000   \n",
       "\n",
       "           compound           Cum  \n",
       "count  10515.000000  10515.000000  \n",
       "mean       0.087019      0.167000  \n",
       "std        0.501812      0.799274  \n",
       "min       -0.979900     -1.000000  \n",
       "25%       -0.296000      0.000000  \n",
       "50%        0.000000      0.000000  \n",
       "75%        0.510600      1.000000  \n",
       "max        0.973200      1.000000  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can see and visualize the counts of all types of news in our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yxE1OVgBf273",
    "outputId": "24a2d6bc-aa7d-4412-a03e-d6164a04c1a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    4383\n",
       " 0    3505\n",
       "-1    2627\n",
       "Name: Polarity, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Polarity'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "id": "AB5-vh4Df274",
    "outputId": "ea6663f2-2755-4d69-a371-2c2c4e45aa29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: 4383 , Negative: 2627 , Neutral: 3505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Sentiment Data Distribution')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "count_pos = df['Polarity'].value_counts()[1]\n",
    "count_ntl = df['Polarity'].value_counts()[0]\n",
    "count_neg = df['Polarity'].value_counts()[-1]\n",
    "\n",
    "print('Positive:', count_pos, ',', 'Negative:', count_neg, ',', 'Neutral:', count_ntl)\n",
    "\n",
    "plt.bar(['Negative', 'Neutral', 'Positive'], [count_neg, count_ntl, count_pos])\n",
    "plt.title(\"Sentiment Data Distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bNKUJtllf274"
   },
   "source": [
    "It's a very good dataset without any skewness. \n",
    "\n",
    "Now let us explore the data we hhave by checking a random sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "id": "ohWZXFXbf274",
    "outputId": "1824accc-ec1e-4a9b-8a5e-52775e203e6a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>News</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>Cum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2020-11-02</td>\n",
       "      <td>NAB again summons Bilawal in fake accounts case</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.4767</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6047</th>\n",
       "      <td>2019-01-14</td>\n",
       "      <td>NHS minister defends increase in drug prices</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.3182</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4950</th>\n",
       "      <td>2018-01-24</td>\n",
       "      <td>Greek economy to grow 2.1pc this year: IOBE th...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.3182</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6045</th>\n",
       "      <td>2019-01-14</td>\n",
       "      <td>RECORDER REPORT: PSX close of day - KARACHI:  ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2906</th>\n",
       "      <td>2015-11-11</td>\n",
       "      <td>LSE downs by 4.04 points - LAHORE: Lahore Stoc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2551</th>\n",
       "      <td>2015-04-13</td>\n",
       "      <td>LSE gains 13.46 points - LAHORE: Lahore Stock ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3120</th>\n",
       "      <td>2016-01-27</td>\n",
       "      <td>Passage of PIA bill in opposition absence not ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.6202</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5133</th>\n",
       "      <td>2018-03-20</td>\n",
       "      <td>RECORDER REPORT: PSX, BRIndex-30 update - KARA...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>2012-04-13</td>\n",
       "      <td>Gold surges to Rs 49,371 - KARACHI: Gold surge...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6898</th>\n",
       "      <td>2019-10-29</td>\n",
       "      <td>Need for encouraging young entrepreneurs stres...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.8910</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date                                               News  Polarity  \\\n",
       "9997 2020-11-02    NAB again summons Bilawal in fake accounts case        -1   \n",
       "6047 2019-01-14       NHS minister defends increase in drug prices         1   \n",
       "4950 2018-01-24  Greek economy to grow 2.1pc this year: IOBE th...         1   \n",
       "6045 2019-01-14  RECORDER REPORT: PSX close of day - KARACHI:  ...         1   \n",
       "2906 2015-11-11  LSE downs by 4.04 points - LAHORE: Lahore Stoc...         0   \n",
       "2551 2015-04-13  LSE gains 13.46 points - LAHORE: Lahore Stock ...         1   \n",
       "3120 2016-01-27  Passage of PIA bill in opposition absence not ...        -1   \n",
       "5133 2018-03-20  RECORDER REPORT: PSX, BRIndex-30 update - KARA...         1   \n",
       "528  2012-04-13  Gold surges to Rs 49,371 - KARACHI: Gold surge...         0   \n",
       "6898 2019-10-29  Need for encouraging young entrepreneurs stres...         1   \n",
       "\n",
       "      Sentiment    neg    neu    pos  compound  Cum  \n",
       "9997         -1  0.307  0.693  0.000   -0.4767   -1  \n",
       "6047          1  0.000  0.723  0.277    0.3182    1  \n",
       "4950          1  0.000  0.924  0.076    0.3182    1  \n",
       "6045          1  0.000  0.870  0.130    0.5574    1  \n",
       "2906          0  0.000  1.000  0.000    0.0000    0  \n",
       "2551          1  0.000  0.802  0.198    0.6369    1  \n",
       "3120         -1  0.153  0.847  0.000   -0.6202   -1  \n",
       "5133          1  0.000  0.870  0.130    0.5574    1  \n",
       "528           0  0.000  0.925  0.075    0.2732    0  \n",
       "6898          1  0.055  0.622  0.323    0.8910    1  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random_idx_list = [random.randint(1,len(df)) for i in range(10)] # creates random indexes to choose from dataframe\n",
    "df.loc[random_idx_list,:].head(10) # Returns the rows with the index and display it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dxNzKULxf275"
   },
   "source": [
    "### Stemming/ Lematization\n",
    "For grammatical reasons, documents are going to use different forms of a word, such as *write, writing and writes.* Additionally, there are families of derivationally related words with similar meanings. The goal of both stemming and lemmatization is to reduce inflectional forms and sometimes derivationally related forms of a word to a common base form.\n",
    "\n",
    "Stemming usually refers to a process that chops off the ends of words in the hope of achieving goal correctly most of the time and often includes the removal of derivational affixes. \n",
    "\n",
    "Lemmatization usually refers to doing things properly with the use of a vocabulary and morphological analysis of words, normally aiming to remove inflectional endings only and to return the base and dictionary form of a word\n",
    "![Stemming and Lematization](https://qph.fs.quoracdn.net/main-qimg-cd7f4bafaa42639deb999b1580bea69f)\n",
    "\n",
    "### Hyperlinks and Mentions\n",
    "News may have tags and hyperlinks in them which may not come in our use so it is important to remove them.\n",
    "\n",
    "### Stopwords\n",
    "Stopwords are commonly used words in English which have no contextual meaning in an sentence. So therefore we remove them before classification. Some stopwords are...\n",
    "![Stopwords English](https://4.bp.blogspot.com/-yiEr-jCVv38/Wmk10d84DYI/AAAAAAAAk0o/IfgjfjpgrxM5NosUQrGw7PtLvgr6DAG8ACLcBGAs/s1600/Screen%2BShot%2B2018-01-24%2Bat%2B5.41.21%2BPM.png)\n",
    "\n",
    "\n",
    "**NLTK** is a python library which got functions to perform text processing task for NLP.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "oIcnbqK6f275"
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "text_cleaning_re = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "No1gdaFyf275"
   },
   "outputs": [],
   "source": [
    "def preprocess(text, stem=False):\n",
    "    text = re.sub(text_cleaning_re, ' ', str(text).lower()).strip()\n",
    "    tokens = []\n",
    "    for token in text.split():\n",
    "        if token not in stop_words:\n",
    "            if stem:\n",
    "                tokens.append(stemmer.stem(token))\n",
    "            else:\n",
    "                tokens.append(token)\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_MEhg-JUf275",
    "outputId": "9dca345f-ba45-4568-f138-ec1b8b65ec42"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CZ\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "def preprocesser(df):\n",
    "    df.text = df['News'].apply(lambda x: preprocess(x))\n",
    "    return df\n",
    "\n",
    "df = preprocesser(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "_x5yWshCCsxj",
    "outputId": "0d3d1f5f-3822-4997-9f89-39dcde5dbb84"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>News</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>Cum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10510</th>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>Court postpones Gilani's indictment till Febru...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.2732</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10511</th>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>Commissioner inaugurates anti-polio campaign -...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10512</th>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>Anti-polio campaign in full swing - Hussain in...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10513</th>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>Procurement of COVID vaccine will take some ti...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.0772</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10514</th>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>Former model Frieha Altaf is the latest target...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date                                               News  Polarity  \\\n",
       "10510 2021-12-01  Court postpones Gilani's indictment till Febru...         0   \n",
       "10511 2021-12-01  Commissioner inaugurates anti-polio campaign -...         0   \n",
       "10512 2021-12-01  Anti-polio campaign in full swing - Hussain in...         0   \n",
       "10513 2021-12-01  Procurement of COVID vaccine will take some ti...         0   \n",
       "10514 2021-12-01  Former model Frieha Altaf is the latest target...         0   \n",
       "\n",
       "       Sentiment   neg    neu    pos  compound  Cum  \n",
       "10510          0  0.07  0.930  0.000   -0.2732    0  \n",
       "10511          0  0.00  1.000  0.000    0.0000    0  \n",
       "10512          0  0.00  1.000  0.000    0.0000    0  \n",
       "10513          0  0.00  0.972  0.028    0.0772    0  \n",
       "10514          0  0.00  1.000  0.000    0.0000    0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qp5uvxOTf276"
   },
   "source": [
    "\n",
    "\n",
    "### Positive Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 840
    },
    "id": "AMdXnWiAf276",
    "outputId": "090da9e8-1165-41b5-93ed-d0e4a5d10245"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date                                               News  Polarity  \\\n",
      "2770  2015-08-26  Stock wobbles persist despite China rate cut -...         1   \n",
      "3602  2016-07-03  Saudi investors keen in investment, joint vent...         1   \n",
      "6966  2019-11-10  AkzoNobel introduces Dulux weathershield - Akz...         1   \n",
      "6967  2019-11-10  Multimodal transport service via train initiat...         1   \n",
      "3620  2016-07-11  Rice export orders to bring relief to farmers ...         1   \n",
      "...          ...                                                ...       ...   \n",
      "1958  2014-10-05  Home work completed to introduce Arabic langua...         1   \n",
      "9956  2020-10-23  Civil awards: Senate body dismayed at lack of ...         0   \n",
      "5600  2018-08-14  Junoon has a new video out for their old class...         0   \n",
      "10389 2021-01-19  Faisal Javed terms PDM protest another attempt...         0   \n",
      "10388 2021-01-19  Federal Cabinet constitutes inquiry committee ...         0   \n",
      "\n",
      "       Sentiment    neg    neu    pos  compound  Cum  \n",
      "2770           1  0.000  0.623  0.377    0.8787    1  \n",
      "3602           1  0.000  0.809  0.191    0.6369    1  \n",
      "6966           1  0.000  0.865  0.135    0.6808    1  \n",
      "6967           1  0.000  0.930  0.070    0.4019    1  \n",
      "3620           1  0.000  0.807  0.193    0.7351    1  \n",
      "...          ...    ...    ...    ...       ...  ...  \n",
      "1958           1  0.000  0.903  0.097    0.4019    1  \n",
      "9956           0  0.258  0.526  0.216   -0.1779    0  \n",
      "5600           0  0.000  1.000  0.000    0.0000    0  \n",
      "10389          0  0.048  0.887  0.065    0.1779    0  \n",
      "10388          0  0.000  0.963  0.037    0.0258    0  \n",
      "\n",
      "[4387 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "plt.figure(figsize = (20,20)) \n",
    "\n",
    "temp = df.sort_values(by=['Polarity'], ascending = False)\n",
    "print(temp[0:count_pos+4])\n",
    "text = ' '.join(temp[\"News\"][0:count_pos])\n",
    "\n",
    "\n",
    "    \n",
    "wc = WordCloud(max_words = 2000 , width = 1600 , height = 800).generate(text)\n",
    "plt.imshow(wc , interpolation = 'bilinear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iqgU70X_f276"
   },
   "source": [
    "### Neutral Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 840
    },
    "id": "Jy0iYoIuf276",
    "outputId": "03543a80-46e5-4e86-91b6-7eca997315c9"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,20)) \n",
    "temp = df.sort_values(by=['Polarity'], ascending = False)\n",
    "print(temp[count_pos:count_pos + count_ntl])\n",
    "text = ' '.join(temp[\"News\"][count_pos:count_pos + count_ntl])\n",
    "\n",
    "\n",
    "    \n",
    "wc = WordCloud(max_words = 2000 , width = 1600 , height = 800).generate(text)\n",
    "plt.imshow(wc , interpolation = 'bilinear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PFM5_swwf277"
   },
   "source": [
    "### Negative Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 840
    },
    "id": "ovyqdgk8f277",
    "outputId": "c367f878-35ab-425a-b71c-58102354a8e4"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,20)) \n",
    "temp = df.sort_values(by=['Polarity'], ascending = False)\n",
    "print(temp[count_pos + count_ntl:])\n",
    "text = ' '.join(temp[\"News\"][count_pos + count_ntl:])\n",
    "\n",
    "\n",
    "    \n",
    "wc = WordCloud(max_words = 2000 , width = 1600 , height = 800).generate(text)\n",
    "plt.imshow(wc , interpolation = 'bilinear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JNOdnQv8f277"
   },
   "source": [
    "## Train and Test Split\n",
    "\n",
    "We split our data in 2 sets, train consisting of 70% data and test consisting of 30% data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9prcK0RCf278"
   },
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 0.3\n",
    "MAX_NB_WORDS = 100000\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "\n",
    "def _train_test_split(df, TRAIN_SIZE):\n",
    "    \n",
    "    train_data, dump = train_test_split(df, test_size=1-TRAIN_SIZE, random_state=7) # Splits Dataset into Training and Testing set\n",
    "    test_data = df.iloc[int(len(df)*0.3):]\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "train_data, test_data = _train_test_split(df, TRAIN_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ed3LDLg1f278",
    "outputId": "6cdfcbff-a3ba-4934-df54-1a161d9aae42"
   },
   "outputs": [],
   "source": [
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LpzTbteTf278"
   },
   "source": [
    "`train_test_split` will shuffle the dataset and split it to gives training and testing dataset. It's important to shuffle our dataset before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "id": "00tKs4Z6f278",
    "outputId": "f1d94e74-9e2d-4aec-d672-cc801d9bf717"
   },
   "outputs": [],
   "source": [
    "train_data.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V4hSYUA4f278"
   },
   "source": [
    "# Tokenization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YOapluXif279",
    "outputId": "3de46217-3f65-44c6-c693-4b0335c8555b"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "def tokenize(train_data):\n",
    "    \n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(train_data['News'])\n",
    "\n",
    "    word_index = tokenizer.word_index\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    return tokenizer, word_index, vocab_size\n",
    "\n",
    "tokenizer, word_index, vocab_size = tokenize(train_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wzlu5o5Rf279",
    "outputId": "2afd3d46-e810-44a2-cc57-bee788c0773d"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def sequence_padder(train_data, MAX_SEQUENCE_LENGTH):\n",
    "\n",
    "    x_train = pad_sequences(tokenizer.texts_to_sequences(train_data['News']),\n",
    "                            maxlen = MAX_SEQUENCE_LENGTH)\n",
    "    x_test = pad_sequences(tokenizer.texts_to_sequences(test_data['News']),\n",
    "                           maxlen = MAX_SEQUENCE_LENGTH)\n",
    "    \n",
    "    return x_train, x_test\n",
    "\n",
    "x_train, x_test = sequence_padder(train_data, MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "print(\"Training X Shape:\",x_train.shape)\n",
    "print(\"Testing X Shape:\",x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wSVFJm9lf27-"
   },
   "source": [
    "### Label Encoding \n",
    "We are building the model to predict class in enocoded form (0 or 1 as this is a binary classification). We should encode our training labels to encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ogTUltnuf27-",
    "outputId": "ce6538ea-2a8e-4008-b4d6-d05c0c936cc7"
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "def encode_labels(train_data, test_data):\n",
    "    \n",
    "    train_labels = to_categorical(train_data['Polarity'], num_classes=3)\n",
    "    test_labels = to_categorical(test_data['Polarity'], num_classes=3)\n",
    "    #labels = np.argmax(labels, axis=1)\n",
    "    y_train = train_labels\n",
    "    y_test = test_labels\n",
    "    return train_labels, test_labels, y_train, y_test\n",
    "\n",
    "train_labels, test_labels, y_train, y_test = encode_labels(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F8sJeh1Af27-",
    "outputId": "f65c621d-2752-4b1f-a28b-2f914ff31c45"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJT2QorIf27-"
   },
   "source": [
    "# Word Emdedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6MMHx-b0f27-"
   },
   "outputs": [],
   "source": [
    "#!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "#!unzip glove.6B.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fMXFHLWvf27_"
   },
   "outputs": [],
   "source": [
    "GLOVE_EMB = 'glove.6B.300d.txt'\n",
    "EMBEDDING_DIM = 300\n",
    "LR = 1e-3\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "MODEL_PATH = 'best_model.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WKRtt9Quf27_",
    "outputId": "91e600bf-f827-4888-8285-1643b46d8d6c"
   },
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "\n",
    "f = open(GLOVE_EMB, encoding=\"utf8\")\n",
    "for line in f:\n",
    "  values = line.split()\n",
    "  word = value = values[0]\n",
    "  coefs = np.asarray(values[1:], dtype='float32')\n",
    "  embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' %len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zoLApLX0f27_"
   },
   "outputs": [],
   "source": [
    "def embedder(EMBEDDING_DIM, vocab_size):\n",
    "    embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
    "    for word, i in word_index.items():\n",
    "      embedding_vector = embeddings_index.get(word)\n",
    "      if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "    embedding_layer = tf.keras.layers.Embedding(vocab_size,\n",
    "                                              EMBEDDING_DIM,\n",
    "                                              weights=[embedding_matrix],\n",
    "                                              input_length=MAX_SEQUENCE_LENGTH,\n",
    "                                              trainable=False)\n",
    "    return embedding_layer\n",
    "\n",
    "embedding_layer = embedder(EMBEDDING_DIM, vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tf6pms1Hf27_"
   },
   "source": [
    "# Model Training - BiDirectional LSTM and Single layer CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t1eWQdx7f27_"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, Bidirectional, LSTM, Dense, Input, Dropout\n",
    "from tensorflow.keras.layers import SpatialDropout1D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lliaJeflf28A",
    "outputId": "84175144-efea-46dc-a5e3-a274357dcf3d"
   },
   "outputs": [],
   "source": [
    "def create_model(MAX_SEQUENCE_LENGTH, embedding_layer):\n",
    "    \n",
    "    sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedding_sequences = embedding_layer(sequence_input)\n",
    "    #x = Sequential()\n",
    "    x = SpatialDropout1D(0.2)(embedding_sequences)\n",
    "    x = Conv1D(64, 5)(x)\n",
    "    x = Bidirectional(LSTM(32, dropout=0.2, recurrent_dropout=0.2))(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    outputs = Dense(3, activation='sigmoid')(x)\n",
    "    print(outputs)\n",
    "    model = tf.keras.Model(sequence_input, outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model(MAX_SEQUENCE_LENGTH, embedding_layer)\n",
    "\n",
    "plot_model(model)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has 1 embedding layer, 1 Convolutional 1D layer with 96,064 parameters, 1 BiDirectional LSTM layer with 24,832 parameters and 2 dense layers with 512 neurons, ReLU activation and 33,280 and 26,2656 parameters each. The final dense layer has 3 output dimensions (good, neutral, bad), Sigmoid activation with 1,539 parameters. There are several dropouts of 20% to ensure there is no overfitting. \n",
    "\n",
    "There are a total of 3,619,071 parameters of which 418,371 are trainable (LSTM and Dense)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QttY6Hdmf28A"
   },
   "source": [
    "\n",
    "\n",
    "### Callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JZSN_VeDf28A"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "def compiler(model, LR):\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=LR), loss='binary_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "    ReduceLROnPlateau_ = ReduceLROnPlateau(factor=0.1,\n",
    "                                         min_lr = 0.01,\n",
    "                                         monitor = 'val_loss',\n",
    "                                         verbose = 1)\n",
    "    \n",
    "    return model, ReduceLROnPlateau_\n",
    "\n",
    "model, ReduceLROnPlateau_ = compiler(model, LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZYJZNBx6f28A",
    "outputId": "0fa66ccc-3f94-4480-bb51-7c8cbd63704a"
   },
   "outputs": [],
   "source": [
    "def fit_model(model, x_train, y_train, BATCH_SIZE, EPOCHS, x_test, y_test):\n",
    "\n",
    "    history = model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
    "                        validation_data=(x_test, y_test), callbacks=[ReduceLROnPlateau_], verbose = 0)\n",
    "    \n",
    "    return history\n",
    "\n",
    "history = fit_model(model, x_train, y_train, BATCH_SIZE, EPOCHS, x_test, y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.models\n",
    "\n",
    "model.save('temp.h5')\n",
    "model = tf.keras.models.load_model('temp' + '.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bJdCqJy1f28B"
   },
   "source": [
    "# Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "lHfrx7OEf28B",
    "outputId": "d1bb4a44-8288-4517-8162-b00ed6cf845d"
   },
   "outputs": [],
   "source": [
    "s, (at, al) = plt.subplots(2,1)\n",
    "at.plot(history.history['acc'], c= 'b')\n",
    "at.plot(history.history['val_acc'], c='r')\n",
    "at.set_title('model accuracy')\n",
    "at.set_ylabel('accuracy')\n",
    "at.set_xlabel('epoch')\n",
    "at.legend(['LSTM_train', 'LSTM_val'], loc='upper left')\n",
    "\n",
    "al.plot(history.history['loss'], c='m')\n",
    "al.plot(history.history['val_loss'], c='c')\n",
    "al.set_title('model loss')\n",
    "al.set_ylabel('loss')\n",
    "al.set_xlabel('epoch')\n",
    "al.legend(['train', 'val'], loc = 'upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jmP10MrJf28B",
    "outputId": "86431c00-cc4d-4179-d885-34039b0793b8"
   },
   "outputs": [],
   "source": [
    "def decode_sentiment(score):\n",
    "    if score[0] > score[1] and score[0] > score[2]:\n",
    "        #print(score[0], '0\\n---')\n",
    "        return 0\n",
    "    elif score[1] > score[0] and score[1] > score[2]:\n",
    "        #print(score[1], '1\\n---')\n",
    "        return 1\n",
    "    elif score[2] > score[0] and score[2] > score[1]:\n",
    "        #print(score[2], '-1\\n---')\n",
    "        return -1\n",
    "\n",
    "def sentiment_decoder(model, x_test):\n",
    "    \n",
    "    scores = model.predict(x_test, verbose=0, batch_size=10)\n",
    "    y_pred_1d = [decode_sentiment(score) for score in scores]\n",
    "    \n",
    "    return scores, y_pred_1d\n",
    "\n",
    "scores, y_pred_1d = sentiment_decoder(model, x_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJR-D04v2NAT",
    "outputId": "62442e01-5d3a-4618-f73c-4d4a063c7bee"
   },
   "outputs": [],
   "source": [
    "len(y_pred_1d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_eAUx2Eif28C"
   },
   "source": [
    "### Confusion Matrix\n",
    "Confusion Matrix provide a nice overlook at the model's performance in classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UUhLpz6qf28C"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, fontsize=13)\n",
    "    plt.yticks(tick_marks, classes, fontsize=13)\n",
    "\n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label', fontsize=17)\n",
    "    plt.xlabel('Predicted label', fontsize=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "id": "d8FnCcP_f28C",
    "outputId": "229199b7-f430-419c-cf85-559e2a32333c"
   },
   "outputs": [],
   "source": [
    "def cnf_plotter(test_data, y_pred_1d):\n",
    "\n",
    "    cnf_matrix = confusion_matrix(test_data['Polarity'].to_list(), y_pred_1d)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plot_confusion_matrix(cnf_matrix, classes=test_data['Polarity'].unique(), title=\"Confusion matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bEO1s70Of28C"
   },
   "source": [
    "### Classification Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JMqIsvn3f28C",
    "outputId": "21f0a794-6a41-4538-9c0e-ef4f6e188b20"
   },
   "outputs": [],
   "source": [
    "print(classification_report(list(test_data['Polarity']), y_pred_1d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run on 100 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KSE100 = pd.read_csv('KSE100.csv')\n",
    "\n",
    "for i in range(76, len(KSE100)):\n",
    "    \n",
    "    print('Iteration:', i)\n",
    "    name = KSE100['Ticker'][i]\n",
    "    print(name)\n",
    "    load_name = 'M2 cleaned files/' + name +'.csv'\n",
    "    load_name_tech = 'Indicators/' + name +'.csv'\n",
    "    \n",
    "    df = load_data(load_name)\n",
    "    df = preprocesser(df)\n",
    "    \n",
    "    train_data, test_data = _train_test_split(df, TRAIN_SIZE)\n",
    "    tokenizer, word_index, vocab_size = tokenize(train_data)\n",
    "    x_train, x_test = sequence_padder(train_data, MAX_SEQUENCE_LENGTH)\n",
    "    train_label, test_labels, y_train, y_test = encode_labels(train_data, test_data)\n",
    "    embedding_layer = embedder(EMBEDDING_DIM, vocab_size)\n",
    "    \n",
    "    model = create_model(MAX_SEQUENCE_LENGTH, embedding_layer)\n",
    "    model, ReduceLROnPlateau_ = compiler(model, LR)\n",
    "    history = fit_model(model, x_train, y_train, BATCH_SIZE, EPOCHS, x_test, y_test)\n",
    "    \n",
    "    model.save('M2 Saved Models/' + name + '.h5')\n",
    "    model = tf.keras.models.load_model('M2 Saved Models/' + name + '.h5')\n",
    "    \n",
    "    scores, y_pred_1d = sentiment_decoder(model, x_test)\n",
    "    \n",
    "    cnf_plotter(test_data, y_pred_1d)\n",
    "    print(classification_report(list(test_data['Polarity']), y_pred_1d))\n",
    "    \n",
    "    output = df.iloc[int(len(df)*TRAIN_SIZE):]\n",
    "    output['Pred'] = y_pred_1d\n",
    "    output = output.reset_index(drop=True)\n",
    "    pred = pd.read_csv(load_name_tech)\n",
    "    pred['Date'] = pd.to_datetime(pred['Date']) \n",
    "    start_date = output['Date'][0]\n",
    "    end_date = pred['Date'][len(pred)-1]\n",
    "\n",
    "    start = pred.index[pred['Date'] == start_date].to_list()[0]\n",
    "    pred = pred.iloc[start:]\n",
    "    end = output.index[output['Date'] == end_date].to_list()[0]\n",
    "    output = output.iloc[:end]\n",
    "    \n",
    "    temp = output.groupby(['Date'], as_index = False).mean()\n",
    "\n",
    "    pred['Score'] = [0 for i in range(len(pred))]\n",
    "\n",
    "    for j in range(len(temp)):\n",
    "\n",
    "        date = temp['Date'][j]\n",
    "\n",
    "        index = pred.index[pred['Date'] == date]\n",
    "\n",
    "        pred['Score'][index] = temp['Pred'][j]\n",
    "\n",
    "    pred.to_csv(path_or_buf = 'M2 output/' + name + '.csv', index = False) #Save dataframe as CSV"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "M2 NLP iqbal.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
